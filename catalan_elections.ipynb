{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# download data from \n",
    "# http://governacio.gencat.cat/ca/pgov_ambits_d_actuacio/pgov_eleccions/pgov_dades_electorals/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INTRODUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regional elections in Catalonia on 27 September 2015  were not ordinary ones. They were a referendum in disguise. A referendum on the independence of Catalonia from the Spanish state. IDESCAT is the national institute of statistics of Catalonia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMPORT AND PROCESS ELECTORAL DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import codes, pct votes, Candid\n",
    "df_pct_vote_info = pd.read_csv('A20151_MU/FilesVots_A20151_MU_ca_ES.csv',sep =';',encoding='latin-1') \n",
    "# turn pct data from strings into integers ( first need to change comma into decimal point)\n",
    "df_pct_vote_info[\"% vàlids\"] = pd.to_numeric(df_pct_vote_info['% vàlids'].str.replace(\",\",\".\")) \n",
    "# make pivot table to rearrange info\n",
    "df_pct_vote_info = df_pct_vote_info.pivot_table(index = [\"Nom Municipi\", \"Codi Municipi\", \"Codi Província\"], columns = \"Candidatures\", values = \"% vàlids\")\n",
    "df_pct_vote_info = df_pct_vote_info.filter( regex = r\"(Junt|Ciuta|Sociali|Partit Pop|es Pot|Unitat|Democr|Codi Mun)\" )\n",
    "# rename columns (change name Candidatures to make it simpler)\n",
    "df_pct_vote_info.columns = [\"CUP_pct\",\"CSQP_pct\",\"Cs_pct\",\"JxSi_pct\",\"PP_pct\",\"PSC_pct\",\"Unio_pct\"]\n",
    "# reset index\n",
    "df_pct_vote_info = df_pct_vote_info.reset_index().set_index('Nom Municipi')\n",
    "## Add columns\n",
    "df_pct_vote_info['Unionisme_pct'] = df_pct_vote_info['Cs_pct'] + df_pct_vote_info['PSC_pct'] + df_pct_vote_info['PP_pct']\n",
    "df_pct_vote_info['Independ_pct'] = df_pct_vote_info['JxSi_pct'] + df_pct_vote_info['CUP_pct']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_codes = pd.read_html('https://www.idescat.cat/codis/?id=50&n=9')[0]\n",
    "df_codes.columns = ['Codi', 'Nom', 'Codi comarca', 'Nom comarca']\n",
    "df_codes = df_codes.set_index('Nom')\n",
    "df_codes.to_csv('Municip_codes_from_IDESCAT.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXAMPLES TO UNDERSTAND DF MERGE, JOIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d1 = pd.DataFrame({'a':[1,2], 'b':[3,4]})\n",
    "d2 = pd.DataFrame({'c':[11,22],'d':[33,44]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  b   c   d\n",
       "0  1  3  11  33\n",
       "1  2  4  22  44"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1.join(d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dummy_1 = pd.DataFrame({'codis':['aa','bb','cc'], 'val1':[2,5,7]}).set_index('codis')\n",
    "dummy_2 = pd.DataFrame({'codis':['aa','bb','dd'], 'val2':[21,52,74]}).set_index('codis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val2</th>\n",
       "      <th>val1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>codis</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aa</th>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bb</th>\n",
       "      <td>52</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dd</th>\n",
       "      <td>74</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       val2  val1\n",
       "codis            \n",
       "aa       21     2\n",
       "bb       52     5\n",
       "dd       74   NaN"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_2.join(dummy_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val1</th>\n",
       "      <th>val2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>codis</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aa</th>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bb</th>\n",
       "      <td>5</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cc</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       val1  val2\n",
       "codis            \n",
       "aa        2    21\n",
       "bb        5    52\n",
       "cc        7   NaN"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_1.join(dummy_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val1</th>\n",
       "      <th>val2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>codis</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aa</th>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bb</th>\n",
       "      <td>5</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cc</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dd</th>\n",
       "      <td>NaN</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       val1  val2\n",
       "codis            \n",
       "aa        2    21\n",
       "bb        5    52\n",
       "cc        7   NaN\n",
       "dd      NaN    74"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(dummy_1, dummy_2, left_index=True, right_index=True, how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.merge(df_pct_vote_info, df_codes, left_index=True, right_index=True, how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# url = 'http://www.idescat.cat/emex/?id=080327'\n",
    "# id_scrap = requests.get(url, headers=headers)\n",
    "# soup = BeautifulSoup(id_scrap.text, \"lxml\")\n",
    "# table = soup.findAll(\"table\", id ='t90')\n",
    "# xx = pd.read_html(str(table), thousands='.')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA SCRAPING FROM IDESCAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "headers = {'User-Agent':\n",
    "           \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_3) AppleWebKit/601.4.4 (KHTML, like Gecko) Version/9.0.3 Safari/601.4.4\"}\n",
    "\n",
    "list_ids = ['t68','t56','t84','t90','t5']\n",
    "labels = ['Pop_struct', 'Unemployment', 'Educ_level', \"Català\", 'Income_level']\n",
    "\n",
    "df_codes = pd.read_csv('Municip_codes_from_IDESCAT.csv')\n",
    "codes, names = df_codes['Codi'].astype(str).str.zfill(6).values, df_codes['Nom'].values\n",
    "\n",
    "all_munic_info = defaultdict(dict)\n",
    "\n",
    "for code, name in zip(codes, names):\n",
    "    print(name)\n",
    "    url = 'http://www.idescat.cat/emex/?id=' + code\n",
    "    req_resp = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(req_resp.text, \"lxml\")\n",
    "    for idx, label in zip(list_ids, labels):\n",
    "        try:\n",
    "            table = soup.findAll(\"table\", id =idx)\n",
    "            values = pd.read_html(str(table), thousands='.')[0][name].str.replace(\",\", \".\").values[:-1]\n",
    "            all_munic_info[name][label] = [float(x) if '.' in x \n",
    "                                           else None if ':' in x  \n",
    "                                           else int(x) \n",
    "                                           for x in values]\n",
    "        except:\n",
    "            all_munic_info[name][label] = []\n",
    "#save data            \n",
    "with open('ALL_MUNICIPAL_DATA.json', 'w') as f:\n",
    "    json.dump(all_munic_info, f)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('ALL_MUNICIPAL_DATA.json') as data_file:    \n",
    "    data = json.load(data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make dataframes from json data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pop_stats, income_stats, ed_level_stats, cat_stats = [], [], [], []\n",
    "names_municips = []\n",
    "for idx, (key, val) in enumerate(data.items()):\n",
    "    pop_stats.append(val['Pop_struct'])\n",
    "    income_stats.append(val['Income_level'])\n",
    "    ed_level_stats.append(val['Educ_level'])\n",
    "    cat_stats.append(val['Català'])\n",
    "    names_municips.append(key)\n",
    "pop_stats = pd.DataFrame(pop_stats, columns =['Cat', 'Spa', 'Abroad', 'Tot'])\n",
    "income_stats = pd.DataFrame(income_stats, columns = ['RFDB', 'RFDB_hab', 'RFDB_idx'])\n",
    "ed_level_stats = pd.DataFrame(ed_level_stats, columns =['ST', '1erGrau', '2nGrau','Univ','Tot_Niv_Ed'])\n",
    "cat_stats = pd.DataFrame(cat_stats, columns = ['understands', 'speaks', 'reads', 'writes', 'no_underst', 'Tot_cat'])\n",
    "names_municips = pd.DataFrame(names_municips, columns=['Municipi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add new columns to data dfs\n",
    "pop_stats['pct_foreign'] = 100 * pop_stats['Abroad'] / pop_stats['Tot']\n",
    "pop_stats['pct_spa'] = 100 * pop_stats['Spa'] / pop_stats['Tot']\n",
    "ed_level_stats['pct_Univ'] = 100 * ed_level_stats['Univ']/ed_level_stats['Tot_Niv_Ed']\n",
    "cat_stats['pct_cat_speakers'] = 100 * cat_stats['speaks'] / cat_stats['Tot_cat']\n",
    "\n",
    "all_stats = pop_stats.join(income_stats).join(ed_level_stats).join(cat_stats).join(names_municips)\n",
    "all_stats = all_stats.set_index('Municipi')\n",
    "\n",
    "# all_stats = pd.merge(pop_stats, ed_level_stats)\n",
    "# all_stats = pd.merge(all_stats, cat_stats).set_index('Municipi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DF_ALL_MUNIC_DATA = df_pct_vote_info.join(all_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DF_ALL_MUNIC_DATA.to_csv('DF_ALL_MUNIC_DATA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Codi Municipi', 'Codi Província', 'CUP_pct', 'CSQP_pct', 'Cs_pct',\n",
       "       'JxSi_pct', 'PP_pct', 'PSC_pct', 'Unio_pct', 'Unionisme_pct',\n",
       "       'Independ_pct', 'Cat', 'Spa', 'Abroad', 'Tot', 'pct_foreign', 'pct_spa',\n",
       "       'RFDB', 'RFDB_hab', 'RFDB_idx', 'ST', '1erGrau', '2nGrau', 'Univ',\n",
       "       'Tot_Niv_Ed', 'pct_Univ', 'understands', 'speaks', 'reads', 'writes',\n",
       "       'no_underst', 'Tot_cat', 'pct_cat_speakers'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF_ALL_MUNIC_DATA.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 100)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.scatter(DF_ALL_MUNIC_DATA['pct_spa'], DF_ALL_MUNIC_DATA['Unionisme_pct'], color='blue', edgecolors='black')\n",
    "plt.scatter(DF_ALL_MUNIC_DATA['pct_spa'], DF_ALL_MUNIC_DATA['Independ_pct'], color='yellow', edgecolors='b')\n",
    "plt.xlim(0, 35)\n",
    "plt.ylim(0, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x11924d400>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#plt.scatter(DF_ALL_MUNIC_DATA['pct_cat_speakers'], DF_ALL_MUNIC_DATA['Unionisme_pct'], s= DF_ALL_MUNIC_DATA['Tot']/100)\n",
    "plt.scatter(DF_ALL_MUNIC_DATA['pct_cat_speakers'], DF_ALL_MUNIC_DATA['Independ_pct'],\n",
    "            edgecolors='b',\n",
    "            s= DF_ALL_MUNIC_DATA['Tot']/100, \n",
    "            color='y',\n",
    "            alpha=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1104ad048>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.scatter(DF_ALL_MUNIC_DATA['pct_cat_speakers'], DF_ALL_MUNIC_DATA['pct_spa'] + DF_ALL_MUNIC_DATA['pct_foreign'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x10fcfcb38>"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.scatter( DF_ALL_MUNIC_DATA['RFDB_idx'], DF_ALL_MUNIC_DATA['Independ_pct'], s= DF_ALL_MUNIC_DATA['Tot']/100, alpha=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           Independ_pct   R-squared:                       0.157\n",
      "Model:                            OLS   Adj. R-squared:                  0.146\n",
      "Method:                 Least Squares   F-statistic:                     13.89\n",
      "Date:                Tue, 29 Aug 2017   Prob (F-statistic):           2.93e-06\n",
      "Time:                        09:55:42   Log-Likelihood:                -616.10\n",
      "No. Observations:                 152   AIC:                             1238.\n",
      "Df Residuals:                     149   BIC:                             1247.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===============================================================================\n",
      "                  coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "-------------------------------------------------------------------------------\n",
      "Intercept      36.6028      4.302      8.508      0.000        28.101    45.104\n",
      "pct_foreign    -0.0280      0.151     -0.185      0.854        -0.327     0.271\n",
      "pct_Univ        0.8116      0.158      5.134      0.000         0.499     1.124\n",
      "==============================================================================\n",
      "Omnibus:                        4.234   Durbin-Watson:                   2.006\n",
      "Prob(Omnibus):                  0.120   Jarque-Bera (JB):                2.703\n",
      "Skew:                           0.126   Prob(JB):                        0.259\n",
      "Kurtosis:                       2.397   Cond. No.                         95.9\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "####STATSMODELS REGRESSION ####################\n",
    "## before symbolic regression get rid of blank spaces in column names\n",
    "DF_ALL_MUNIC_DATA.columns = DF_ALL_MUNIC_DATA.columns.str.replace(\" \",\"_\")\n",
    "#import libraries\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "## Fit regression model()\n",
    "results = smf.ols(\"Independ_pct ~ pct_foreign + pct_Univ \", data = DF_ALL_MUNIC_DATA).fit()\n",
    "## Inspect the results\n",
    "print ( results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## IMPORT LIBRARIES\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.collections import PatchCollection\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from shapely.geometry import Point, Polygon, MultiPoint, MultiPolygon\n",
    "from shapely.prepared import prep\n",
    "from pysal.esda.mapclassify import Natural_Breaks as nb\n",
    "from descartes import PolygonPatch\n",
    "import fiona ## to read shapefiles\n",
    "from itertools import chain\n",
    "import pysal.esda.mapclassify as mapclassify\n",
    "import shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class mapviz():\n",
    "    \"\"\" Input data, map file and column to be visualized\"\"\"\n",
    "\n",
    "    def __init__(self, datafile, shapefile, var_to_plot):\n",
    "        self.datafile = datafile\n",
    "        self.shapefile = shapefile\n",
    "        self.var_to_plot = var_to_plot\n",
    "\n",
    "############ IMPORT DATASET\n",
    "\n",
    "## read in electoral data\n",
    "\n",
    "    def load_data(self):\n",
    "        data = pd.read_csv(self.datafile,encoding='latin-1')\n",
    "        self.data = data.rename(columns = {\"Codi Municipi\":\"Codi_Municipi\"})\n",
    "\n",
    "\n",
    "\n",
    "##########LOAD SHAPEFILE using FIONA ( the pythonic way)\n",
    "## SHAPEFILE and FIONA are modules to read in shapefiles content\n",
    "## SHAPELY is a module to manipulate shapefiles\n",
    "##load the shape file as shp.\n",
    "##your shapefile should end in .shp\n",
    "\n",
    "    def load_geo_limits(self):\n",
    "        shp = fiona.open(self.shapefile)\n",
    "\n",
    "## fiona.open gives a fiona collection, and each element of the collection\n",
    "## is a dict with keys ['id', 'geometry', 'properties', 'type']\n",
    "## so it's easy to explore it all\n",
    "\n",
    "#we can access the boundaries (the 2 lat,long pairs) using shp.bounds\n",
    "        self.bds = shp.bounds\n",
    "\n",
    "#close the shp file\n",
    "        shp.close()\n",
    "\n",
    "#define a variable called extra which we will use for padding the map when we display it (in this case I've selected a 10% pad)\n",
    "        self.extra = 0.1\n",
    "\n",
    "#define the lower left hand boundary (longitude, latitude)\n",
    "        ll = (self.bds[0], self.bds[1])\n",
    "\n",
    "#define the upper right hand boundary (longitude, latitude)\n",
    "        ur = (self.bds[2], self.bds[3])\n",
    "\n",
    "#concatenate the lower left and upper right into a variable called coordinates\n",
    "        self.coords = list(chain(ll, ur))\n",
    "\n",
    "#define variables for the width and the height of the map\n",
    "        self.w, self.h = self.coords[2] - self.coords[0], self.coords[3] - self.coords[1]\n",
    "\n",
    "###PLOT WITH BASEMAP ##################\n",
    "####CREATE BASEMAP\n",
    "\n",
    "    def apply_basemap(self):\n",
    "        m = Basemap(\n",
    "            #set projection to 'tmerc' which is apparently less distorting when close-in\n",
    "            projection='tmerc',\n",
    "\n",
    "            #set longitude as average of lower, upper longitude bounds\n",
    "            lon_0 = np.average([self.bds[0],self.bds[2]]),\n",
    "\n",
    "            #set latitude as average of lower,upper latitude bounds\n",
    "            lat_0 = np.average([self.bds[1],self.bds[3]]),\n",
    "\n",
    "            #string describing ellipsoid (‘GRS80’ or ‘WGS84’, for example). Not sure what this does...\n",
    "            ellps = 'WGS84',\n",
    "            \n",
    "            #set the map boundaries. Note that we use the extra variable to provide a 10% buffer around the map\n",
    "            llcrnrlon=self.coords[0] - self.extra * self.w,\n",
    "            llcrnrlat=self.coords[1] - self.extra + 0.01 * self.h,\n",
    "            urcrnrlon=self.coords[2] + self.extra * self.w,\n",
    "            urcrnrlat=self.coords[3] + self.extra + 0.01 * self.h,\n",
    "\n",
    "            #provide latitude of 'true scale.' Not sure what this means, I would check the Basemap API if you are a GIS guru\n",
    "            lat_ts=0,\n",
    "\n",
    "            #resolution of boundary database to use. Can be c (crude), l (low), i (intermediate), h (high), f (full) or None.\n",
    "            resolution='i',\n",
    "            \n",
    "            #don't show the axis ticks automatically\n",
    "            suppress_ticks=True)\n",
    "\n",
    "        m.readshapefile(\n",
    "            #provide the path to the shapefile, but leave off the .shp extension\n",
    "            'CAT_municipis_shp/municipis',\n",
    "\n",
    "            #name your map something useful (I named this 'srilanka')\n",
    "            'municipis',\n",
    "\n",
    "            #set the zorder (layer order).Black is default color\n",
    "            zorder=2,\n",
    "            \n",
    "            #set encoding to read Catalan names\n",
    "            default_encoding = 'latin-1')\n",
    "\n",
    "        self.m = m\n",
    "\n",
    "\n",
    "\n",
    "### SETTING UP DATAFRAME ######### ALTERNAT : use GEOPANDAS\n",
    "# set up a map dataframe\n",
    "\n",
    "    def set_up_DF(self):\n",
    "        df_map = pd.DataFrame({\n",
    "\n",
    "            #access the x,y coords and define a polygon for each item in m.srilanka\n",
    "            # This uses Basemap code that already projects long,lat coords\n",
    "            'poly': [Polygon(xy) for xy in self.m.municipis],\n",
    "            #conver NAME_1 to a column called 'district'\n",
    "            \"Codi_Municipi\": [district['Codigo'] for district in self.m.municipis_info],\n",
    "            'nom': [district['Texto'] for district in self.m.municipis_info]})\n",
    "\n",
    "        df_map[\"Codi_Municipi\"] = pd.to_numeric(df_map[\"Codi_Municipi\"])\n",
    "\n",
    "        ### MERGE ##########\n",
    "        self.df_map = pd.merge(df_map, self.data, on=\"Codi_Municipi\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "####PLOT #####\n",
    "\n",
    "#############\n",
    "    def plot(self):\n",
    "\n",
    "        # define the figure and set the facecolor (e.g. background) to white\n",
    "        fig = plt.figure(facecolor='white')\n",
    "\n",
    "        # ad a subplot called 'ax'\n",
    "        ax = fig.add_subplot(111, axisbg='w', frame_on=False)\n",
    "\n",
    "        # use a blue colour ramp ('Blues') - we'll be converting it to a map using cmap()\n",
    "        # you could also use 'Oranges' or 'Greens' \n",
    "        cmap = plt.get_cmap('YlOrRd')\n",
    "\n",
    "        # Use descartes to create shapely patches from Nx2 arrays of points\n",
    "        # Use pandas map to apply to entire column\n",
    "        # draw district with grey outlines\n",
    "        self.df_map['patches'] = self.df_map['poly'].map(lambda x: PolygonPatch(x, ec='#555555', lw=.2, alpha=1., zorder=4))\n",
    "\n",
    "\n",
    "        # set the PatchCollection with our defined 'patches'\n",
    "        pc = PatchCollection(self.df_map['patches'], match_original=True)\n",
    "        ax.add_collection(pc)\n",
    "        ax.plot()\n",
    "\n",
    "        # normalize our bins between the min and max values within the bins\n",
    "        norm = Normalize(vmin=0., vmax= 100.)\n",
    "\n",
    "        # impose our color map onto the patch collection\n",
    "        \n",
    "        pc.set_facecolor(cmap(norm(self.df_map[self.var_to_plot].values)))\n",
    "\n",
    "        ##since patches are not mapped, use proxy mappable object\n",
    "        mappable = cm.ScalarMappable(cmap=cmap)\n",
    "        mappable.set_array(self.df_map[self.var_to_plot].values)\n",
    "        colorbar = plt.colorbar(mappable)\n",
    "        plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_class = mapviz(\"DF_ALL_MUNIC_DATA.csv\",\"CAT_municipis_shp/municipis.shp\",\"Independ_pct\")\n",
    "my_class.load_data()\n",
    "my_class.load_geo_limits()\n",
    "my_class.apply_basemap()\n",
    "my_class.set_up_DF()\n",
    "my_class.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
